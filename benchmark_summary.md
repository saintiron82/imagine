# Batch Processing Performance Benchmark Results

## Test Configuration
- **Date**: 2026-02-09
- **System**: Windows (CUDA)
- **Test Files**: 20 files (mixed PSD/PNG)
- **Tiers**: Standard, Pro, Ultra

---

## Results Summary

### Standard Tier (Transformers - moondream2) âœ…

| Files | Total Time | Avg Time/File | Speedup |
|-------|------------|---------------|---------|
| 1     | 12.2s      | 12.2s         | 1.0x    |
| 5     | 14.9s      | 3.0s          | **4.1x** |
| 10    | 17.0s      | 1.7s          | **7.2x** |
| 20    | 17.4s      | 0.9s          | **13.6x** |

**Key Findings:**
- Batch efficiency increases exponentially with batch size
- Peak efficiency at 20 files: 13.6x faster than sequential
- Excellent parallelization with Transformers backend

---

### Pro Tier (Transformers - Qwen3-VL-4B) âš ï¸

| Files | Total Time | Avg Time/File | Speedup | Status |
|-------|------------|---------------|---------|--------|
| 1     | 17.5s      | 17.5s         | 1.0x    | âœ… |
| 5     | 24.6s      | 4.9s          | 3.6x    | âœ… |
| 10    | 37.6s      | 3.8s          | 4.6x    | âœ… |
| 20    | -          | -             | -       | âŒ **FAILED** |

**Key Findings:**
- Moderate batch efficiency (4-5x improvement)
- **System limit reached at 20 files** (VRAM/Memory exhaustion)
- Larger model = lower parallelization efficiency

---

### Ultra Tier (Ollama - qwen3-vl:8b) ðŸ”„

| Files | Total Time | Avg Time/File | Status |
|-------|------------|---------------|--------|
| 1     | 51.0s      | 51.0s         | âœ… |
| 5     | -          | -             | ðŸ”„ In Progress |
| 10    | -          | -             | â³ Pending |
| 20    | -          | -             | â³ Pending |

**Key Findings (Partial):**
- Significantly slower than Transformers backend (3x slower)
- Single file: 51s vs 17.5s (Pro) vs 12.2s (Standard)

---

## Critical Observations

### 1. System-Specific Limits
- **Pro tier fails at 20 files** â†’ VRAM/memory constraint
- Optimal batch size varies by tier and hardware
- **AUTO mode is essential for production use**

### 2. Thermal Throttling Effects
- Performance degradation observed during long runs
- System temperature impacts processing speed
- Dynamic adjustment needed for sustained operations

### 3. Backend Performance
- **Transformers >> Ollama** (3-5x faster for similar models)
- Standard tier has best parallelization efficiency
- Larger models = diminishing parallel returns

---

## Recommendations

### For Current System:
- **Standard tier**: Use batch size 16-20 (optimal)
- **Pro tier**: Use batch size 8-10 (safe limit)
- **Ultra tier**: Await full results

### For Production:
1. **Implement AUTO calibration mode**
   - Logarithmic search: 1, 2, 4, 8, 16, 32...
   - Detect system limits automatically
   - Apply 80% safety margin

2. **Add thermal monitoring**
   - Track performance degradation
   - Reduce batch size on throttling
   - Maintain consistent throughput

3. **Fallback on failure**
   - Retry with smaller batch on OOM
   - Graceful degradation to sequential

---

## Performance Comparison

**Processing 100 files:**

| Tier | Batch Size | Estimated Time | vs Sequential |
|------|------------|----------------|---------------|
| Standard | 1 (sequential) | 20 min 20s | baseline |
| Standard | 20 (batch) | **1 min 30s** | **13.6x faster** |
| Pro | 1 (sequential) | 29 min 10s | baseline |
| Pro | 10 (batch) | **6 min 17s** | **4.6x faster** |

**Conclusion**: AUTO batch mode can reduce processing time from 20+ minutes to under 2 minutes for 100 files on this system.
