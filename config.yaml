ai_mode:
  auto_detect: false
  override: standard
  tiers:
    pro:
      preprocess:
        aspect_ratio_mode: contain
        max_edge: 768
        padding_color: '#FFFFFF'
      text_embed:
        dimensions: 1024
        model: qwen3-embedding:0.6b
      visual:
        dimensions: 1152
        model: google/siglip2-so400m-patch14-384
      vlm:
        backend: transformers
        device: auto
        model: Qwen/Qwen3-VL-4B-Instruct
      vram_max: 16384
      vram_min: 8192
    standard:
      preprocess:
        aspect_ratio_mode: contain
        max_edge: 512
        padding_color: '#FFFFFF'
      text_embed:
        dimensions: 256
        model: qwen3-embedding:0.6b
        normalize: true
      visual:
        dimensions: 768
        model: google/siglip2-base-patch16-224
      vlm:
        backend: transformers
        device: auto
        model: Qwen/Qwen3-VL-2B-Instruct
      vram_max: 6144
    ultra:
      preprocess:
        aspect_ratio_mode: contain
        max_edge: 1024
        padding_color: '#FFFFFF'
      text_embed:
        dimensions: 4096
        model: qwen3-embedding:8b
      visual:
        dimensions: 1664
        model: google/siglip2-giant-opt-patch16-256
      vlm:
        # Backend: 'auto' enables platform-specific optimization
        backend: auto
        device: auto
        dtype: bfloat16
        model: qwen3-vl:8b

        # Platform-specific configurations (used when backend=auto)
        backends:
          windows:
            backend: ollama
            model: qwen3-vl:8b
            batch_size: 1  # Ollama Vision API: sequential only

          darwin:  # macOS
            backend: vllm  # Preferred for batch processing
            model: Qwen/Qwen3-VL-8B-Instruct
            batch_size: 16  # vLLM supports excellent batching
            fallback: ollama  # If vLLM not installed

          linux:
            backend: vllm  # Preferred for batch processing
            model: Qwen/Qwen3-VL-8B-Instruct
            batch_size: 16
            fallback: ollama
      vram_min: 20480
embedding:
  # NOTE: These are FALLBACK values. Tier-specific config (ai_mode.tiers.{tier})
  # takes precedence at runtime. These values are only used when tier config is missing.
  text:
    dimensions: 1024
    enabled: true
    instruction_prefix: ''
    model: qwen3-embedding:0.6b
  visual:
    dimensions: 1152
    model: google/siglip2-so400m-patch16-naflex
runtime:
  ollama_version: 0.15.2
  pin_version: false
batch_processing:
  enabled: true  # Enable adaptive batch processing (GUI configurable)
search:
  candidate:
    fts_topn_cut: 2000
    full_scan_threshold: 10000
    hard_no_full_scan: true
    no_cut_if_under: 200
  fts:
    bm25_weights:
      meta_strong: 3
      meta_weak: 1.5
  rrf:
    candidate_multiplier: 5
    k: 60
    preset: balanced
    presets:
      balanced:
        m: 0.3
        s: 0.4
        v: 0.3
      keyword:
        m: 0.4
        s: 0.35
        v: 0.25
      fact:
        m: 0.6
        s: 0.25
        v: 0.15
      semantic:
        m: 0.25
        s: 0.55
        v: 0.2
      visual:
        m: 0.15
        s: 0.35
        v: 0.5
  threshold:
    text_vec: 0.15
    visual: 0.05
storage:
  path_style: posix
thumbnail:
  format: png
  index_composite_bg: '#FFFFFF'
  keep_alpha: true
  max_size: 1024
vision:
  keep_alive: 5m
  max_retries: 2
  model: qwen3-vl:8b
  ollama_host: http://localhost:11434
  temperature: 0.1
