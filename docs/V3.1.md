# ImageParser 개발명세서 v3.1 (VV/MV/MC 기반 Final)

**버전:** v3.1  
**범위:** 데이터 구축(인제스트) + 검색 방법 + 작업 명세(Implementation Plan)  
**목표:** 개인 사용자 로컬 에셋(이미지/PSD/UI/배경/아이템)에서 **시각+의미+팩트** 기반 검색 품질을 상용 수준으로 끌어올림  
**핵심 원칙:** 축을 늘리지 않는다. **의미 벡터(MV)의 입력 품질을 Context Injection으로 고급화**하고, 검색 실행은 **Candidate First → Scoring Later**로 안정화한다.

---

## 0. 용어 정의 (Glossary)

### VV (Visual Vector)
- **정의:** 표준화된 썸네일 이미지에서 추출한 **VV 벡터**
- **역할:** “겉모습/스타일/구도/색감” 유사도 검색
- **모델:** SigLIP 2 (image encoder)

### MC (Meta Caption Package)
MC는 “벡터가 아닌” **근거 데이터 패키지**이며, 2개 계층으로 구성한다.

#### MC 2-1) MC.raw (팩트/원본 컨텍스트)
- **구성:** 파일 메타(경로/확장자/폴더), 유저 태그/노트/캡션, PSD 레이어/폰트/텍스트 파싱 결과, OCR 텍스트 등
- **역할:**  
  1) 후보군 생성(필터/FTS)용 **팩트 데이터**  
  2) Qwen3 캡션 생성(2-2)과 MV 생성의 **입력 재료**

#### MC 2-2) MC.caption (Qwen3 통합 해석 캡션)
- **정의:** Qwen3-VL이 **이미지 + MC.raw**를 참고해 생성한 “통합 해석 텍스트”
- **역할:**  
  1) 사용자 표시용 의미 설명(정보)  
  2) MV 생성의 **입력 소스**

### MV (Meaning Vector)
- **정의:** MC.caption(통합 해석 캡션)을 임베딩한 **의미 임베딩 벡터**
- **역할:** 자연어 의미/맥락/용도 유사도 검색
- **모델:** Qwen3-Embedding-0.6B (text embedding)

### FTS (Factual Search)
- **정의:** 정확 키워드/필드 매칭(파일명/레이어명/폰트/OCR/유저태그 등)
- **원칙:** **팩트 우선**, 생성 캡션은 보조

---

## 1. 최종 데이터 흐름 (Pipeline)

### 1.1 인제스트(구축)
1. **썸네일 표준화**(강제)  
2. **MC 2-1 생성:** 메타/유저/PSD 레이어/OCR 등 raw 팩트 구축  
3. **MC 2-2 생성:** Qwen3-VL에 이미지+MC.raw 주입 → 통합 해석 캡션 생성  
4. **VV 생성:** SigLIP2로 이미지 임베딩  
5. **MV 생성:** Qwen3-Embedding으로 MC.caption 임베딩  
6. **FTS 인덱싱:** fts_metadata(팩트) / fts_caption(생성) 구축  
7. **중복키 저장:** perceptual_hash(64-bit int) + (옵션) dup_group_id

### 1.2 검색(실행)
- **Candidate First → Scoring Later**
1. Query Assembly(Fusion Plan)  
2. Candidate Generation(WHERE + FTS로 후보 doc_id 선정, 부족/과다 시 완화/제한)  
3. Scoring(VV/MV/FTS에 대해 후보군만 점수 산출)  
4. RRF(또는 weighted RRF)로 통합 랭킹  
5. De-dup 그룹핑(perceptual_hash/dup_group_id) 후 최종 결과

---

## 2. 썸네일 표준화 규격 (필수)

**출력 포맷:** PNG  
**컬러:** sRGB  
**최대 변:** 1024px (비율 유지)  
**알파 처리:** 정책 고정(예: 투명 배경은 체크보드 합성 또는 단색 배경 합성 중 하나로 통일)  
**입력 통일:** perceptual_hash / VV는 **반드시 표준화된 썸네일**로부터 계산

> 표준화는 “품질 기능”이 아니라 **검색 품질을 결정하는 규격**이다.

---

## 3. MC(Meta Caption) 생성 규칙

### 3.1 MC.raw 수집 항목(최소)
- file_path(원본), storage_root, relative_path(정규화)
- file_extension, format
- user_tags, user_note, user_caption(사용자 제공 설명)
- ocr_text
- PSD 파싱(가능한 범위):
  - layer_names(중요도 기반 상위 N개)
  - text_layers(텍스트 내용은 길이 제한)
  - used_fonts
  - (선택) 그룹 구조, visible/hidden 등

### 3.2 Qwen3 캡션 생성(Context Injection)
**입력:** 이미지(썸네일) + MC.raw  
**출력:** MC.caption(통합 해석 텍스트) + tags + structured_meta

**출력 최소 요구:**
- `mc_caption`: 1~2문장(“무엇/어떤 맥락/용도”)
- `ai_tags`: 최대 10개
- `structured_meta`: image_type + 타입별 핵심 필드(scene_type/ui_type/item_type 등)

---

## 4. MV 입력 포맷(고정) — v3.1 최종

MV(Meaning Vector)는 **MC.caption(통합 해석 캡션)**을 중심으로 생성하며, 임베딩 입력 텍스트는 **[SEMANTIC] / [FACTS]**의 2-블록 구조로 **항상 동일 포맷**을 사용한다.  
(캡션 생성 단계와 임베딩 단계의 포맷을 통일하여 파이프라인 복잡도를 최소화한다.)

### 4.1 MV 임베딩 입력 템플릿

```text
[SEMANTIC]
{mc_caption}
Keywords: {tag1, tag2, ...}

[FACTS]
{trimmed_facts}
```

### 4.2 필드 규칙
- `{mc_caption}`: Qwen3-VL이 생성한 **Context-Aware Caption** (1~2문장 권장)
- `Keywords`: `ai_tags` 또는 캡션에서 추출/정제된 키워드(최대 10개)
- `{trimmed_facts}`: MC.raw에서 추출한 팩트의 **요약본**
  - 권장 표현: `key=value` 형태로 간결하게 나열(줄바꿈 또는 `;` 구분)
  - 예시:
    - `image_type=background; scene_type=alley; time_of_day=night; weather=rain`
    - `fonts=NotoSans; ocr="GAME OVER"; path=assets/UI/`

### 4.3 원칙
- **SEMANTIC 블록은 “의미/맥락/용도” 중심**, FACTS 블록은 **관측된 팩트(메타/레이어/OCR/유저정보)** 중심으로 유지한다.
- FACTS 블록에는 가능한 한 **추론/서술형 문장**을 넣지 않는다(팩트 순도 유지).
- 이 포맷은 모든 파일 타입(PSD/PNG/JPG 등)에 대해 동일하게 적용한다.

---

## 5. FTS 설계(팩트 우선)

### 5.1 fts_metadata (High)
- file_name, path/relative_path
- layer_names
- used_fonts
- user_tags, user_note, user_caption
- ocr_text
- (선택) image_type/scene_type/ui_type 등 구조화 필드 텍스트화

### 5.2 fts_caption (Low)
- mc_caption(통합 해석 캡션)
- ai_tags

> 원칙: “Shadow” 같은 검색에서 **레이어명 Shadow가 최상위**, 캡션의 shadowy는 하위.

---

## 6. 검색 실행 로직 v3.1 (Candidate First → Scoring Later)

### Step 1) Query Assembly (Fusion Plan)
입력(멀티 레인 가능): 텍스트 쿼리 N개 + 이미지 쿼리(옵션)  
출력: `filters`, `fts_meta_query`, `fts_caption_query(옵션)`, `vv_query_source(text/image)`, `mv_query_text`

- 멀티 레인은 **결과 교집합이 아니라 “쿼리 조건 조립”**이 기본
- AND/OR는 QueryPlan 레벨에서 조립

### Step 2) Candidate Generation
**기본 후보군 생성:**  
- SQL WHERE(구조화 컬럼 필터) + `fts_metadata MATCH`  
- 후보 `doc_id` 리스트 획득

**정책:**
- 후보가 너무 적으면(예: `< min_candidates`) → 필터/키워드 완화
- 후보가 너무 많으면(예: `> max_candidates`) → 후보 Top-N 제한 또는 추가 조건 강화

### Step 3) Scoring & Merge
후보 `doc_id`에 대해서만:
- VV 점수: 이미지/텍스트 인코딩 후 벡터 유사도
- MV 점수: MV 유사도
- FTS 점수: fts_metadata 랭킹 + (옵션) fts_caption 랭킹

통합:
- 기본: RRF (rank 기반)
- (옵션) auto-weighted RRF는 별도 단계에서 활성화

### Step 4) De-dup Grouping
- `dup_group_id`가 있으면 우선 그룹
- 없으면 `perceptual_hash` 동일 그룹(약한 중복 제거)
- 그룹 대표는 fused score 최고 1개

---

## 7. DB 스키마(v3.1 핵심)

### 7.1 files 테이블(핵심 컬럼)
- 경로:
  - `storage_root TEXT`
  - `relative_path TEXT`
- 구조화:
  - `image_type, art_style, color_palette, scene_type, time_of_day, weather, ui_type, item_type, character_type ...`
  - `structured_meta TEXT` (JSON)
- 텍스트:
  - `ocr_text TEXT`
  - `user_note TEXT`
  - `user_tags TEXT`
  - `user_caption TEXT` (선택)
  - `mc_caption TEXT` (Qwen 생성 통합 해석 캡션)
  - `ai_tags TEXT` (선택: JSON 또는 delimiter)
- 벡터:
  - `vv_embedding BLOB` (sqlite-vec)
  - `mv_embedding BLOB` (sqlite-vec)
- 중복:
  - `perceptual_hash INTEGER` (64-bit)
  - `dup_group_id INTEGER`
- 버전:
  - `embedding_model TEXT`
  - `embedding_version INTEGER`

### 7.2 FTS 테이블 분리
- `files_fts_meta` (팩트)
- `files_fts_caption` (생성)

(트리거로 files insert/update 시 동기화)

---

## 8. 작업명세서 (Implementation Plan v3.1)

### P0-1: DB 마이그레이션
- [ ] `files` 테이블에 `perceptual_hash INTEGER`, `dup_group_id INTEGER` 추가
- [ ] `mc_caption TEXT` 컬럼 추가
- [ ] `files_fts_meta`, `files_fts_caption` 생성 및 트리거 구성
- [ ] 인덱스 생성:
  - `idx_phash(perceptual_hash)`
  - `idx_dup_group(dup_group_id)`
  - `idx_relative_path(relative_path)`
  - `idx_image_type(image_type)` 등

### P0-2: 인제스트 엔진 수정
- [ ] 썸네일 표준화 강제(1024px/PNG/sRGB/알파정책)
- [ ] MC.raw 수집 구현:
  - 유저 태그/노트/캡션
  - PSD 레이어/폰트/텍스트 파싱 결과
  - OCR 텍스트(기본)
- [ ] Qwen3-VL Context Injection 캡션 생성(MC.caption → `mc_caption`)
- [ ] VV 생성(SigLIP2 image embedding → `vv_embedding`)
- [ ] MV 생성(Qwen3-Embedding on **섹션 4 포맷** → `mv_embedding`)
- [ ] `perceptual_hash`(dHash64) 계산 후 INTEGER 저장

### P0-3: 검색 엔진 수정(`sqlite_search.py`)
- [ ] Query Assembly(Fusion Plan) 구현(멀티 레인 포함)
- [ ] `_get_candidates()` 구현:
  - WHERE + `fts_metadata MATCH`
  - 부족/과다 시 완화/제한 정책 적용
- [ ] `_score_candidates()` 구현:
  - 후보에 대해 VV/MV/FTS 점수 계산
  - RRF 통합
- [ ] 결과 De-dup Grouping(perceptual_hash/dup_group_id) 적용

### P0-4: 데이터 갱신 정책(메타 수정)
- [ ] user_note/user_tags/user_caption 변경 시:
  - fts_metadata 즉시 갱신
- [ ] `mc_caption`/MV 재생성은 정책 기반(즉시 또는 배치)으로 분리(기본은 배치 권장)

---

## 9. 완료 기준(Definition of Done)
- 인제스트 결과로 각 파일에:
  - VV, MC(raw+caption), MV, fts_metadata 인덱싱, perceptual_hash 저장이 모두 존재
- 검색은:
  - 멀티 쿼리 입력 시 “쿼리 조립 후 단일 실행 플로우”로 동작
  - 후보군 기반으로 벡터 계산이 이루어져 전체 스캔이 발생하지 않음
  - 중복 이미지가 결과 상단을 도배하지 않음(그룹핑/대표 출력)
