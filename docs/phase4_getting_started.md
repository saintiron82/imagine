# Phase 4 ì‹œì‘ ê°€ì´ë“œ (Getting Started)

## ğŸ“‹ ì‘ì—… ì‹œì‘ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… 1ë‹¨ê³„: í™˜ê²½ í™•ì¸

```powershell
# Python í™˜ê²½ í™•ì¸
python --version
# ì˜ˆìƒ: Python 3.11.9

# GPU í™•ì¸
nvidia-smi
# ì˜ˆìƒ: RTX 3060 Ti, CUDA 12.6

# ê°€ìƒ í™˜ê²½ í™œì„±í™” í™•ì¸
python -c "import sys; print(sys.executable)"
# ì˜ˆìƒ: C:\Users\saint\ImageParser\.venv\Scripts\python.exe
```

**ì²´í¬:**
- [x] Python 3.11.9
- [x] NVIDIA RTX 3060 Ti (8GB)
- [x] ê°€ìƒ í™˜ê²½ í™œì„±í™”ë¨

---

### âš ï¸ 2ë‹¨ê³„: í•µì‹¬ ì˜ì¡´ì„± ì„¤ì¹˜ (CRITICAL)

**í˜„ì¬ ìƒíƒœ:**
```json
{
  "torch": false,              // âŒ ë¯¸ì„¤ì¹˜
  "chromadb": false,           // âŒ ë¯¸ì„¤ì¹˜
  "sentence-transformers": false, // âŒ ë¯¸ì„¤ì¹˜
  "pillow": false              // âŒ ë¯¸ì„¤ì¹˜
}
```

**ì„¤ì¹˜ ëª…ë ¹ì–´:**

```powershell
# ë°©ë²• 1: ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ (ê¶Œì¥)
python backend/setup/installer.py --install
python backend/setup/installer.py --download-model

# ë°©ë²• 2: ìˆ˜ë™ ì„¤ì¹˜
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install chromadb sentence-transformers pillow transformers timm einops

# ì„¤ì¹˜ ê²€ì¦
python backend/setup/installer.py --check
```

**ì˜ˆìƒ ì„¤ì¹˜ ì‹œê°„:** 5-10ë¶„ (ì¸í„°ë„· ì†ë„ì— ë”°ë¼)
**ë””ìŠ¤í¬ ê³µê°„ ìš”êµ¬:** ~5GB (PyTorch + CLIP ëª¨ë¸)

---

### ğŸ“¦ 3ë‹¨ê³„: Phase 4 ì „ìš© ì˜ì¡´ì„± ì¶”ê°€

**requirements.txt ì—…ë°ì´íŠ¸:**

```bash
# Phase 4 ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬
transformers>=4.40.0    # HuggingFace Transformers (Florence-2)
timm>=0.9.0            # PyTorch Image Models
einops>=0.7.0          # Tensor ì—°ì‚° í—¬í¼
```

**ì„¤ì¹˜:**
```powershell
pip install transformers>=4.40.0 timm>=0.9.0 einops>=0.7.0
```

**ê²€ì¦:**
```powershell
python -c "from transformers import AutoProcessor, AutoModelForCausalLM; print('Transformers OK')"
```

---

### ğŸ§ª 4ë‹¨ê³„: ê¸°ì¡´ ì‹œìŠ¤í…œ ê²€ì¦

**Phase 1-3ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸:**

```powershell
# 1. ìŠ¤í‚¤ë§ˆ import í…ŒìŠ¤íŠ¸
python -c "from backend.parser.schema import AssetMeta; print('Schema OK')"

# 2. íŒŒì„œ í…ŒìŠ¤íŠ¸
python test_image_parser.py

# 3. ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (ì˜ì¡´ì„± ì„¤ì¹˜ í›„)
python backend/pipeline/ingest_engine.py --file "test_assets/sample.png"

# 4. ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
python backend/cli_search.py "test query"
```

**ì˜ˆìƒ ê²°ê³¼:**
- âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ PASS
- âœ… `output/json/sample.json` ìƒì„±ë¨
- âœ… `chroma_db/` ì—…ë°ì´íŠ¸ë¨

**ë¬¸ì œ ë°œìƒ ì‹œ:**
- `docs/troubleshooting.md` ì°¸ì¡°
- `/troubleshoot` ëª…ë ¹ì–´ë¡œ ë¬¸ì œ ê¸°ë¡

---

## ğŸš€ Phase 4 ì‘ì—… ì‹œì‘

### U-015 ì‹œì‘ ì¤€ë¹„

**1. ë””ë ‰í† ë¦¬ ìƒì„±:**
```powershell
mkdir backend\vision
New-Item backend\vision\__init__.py -ItemType File
New-Item backend\vision\analyzer.py -ItemType File
```

**2. ìœ ë‹› ê°œë°œ í”„ë¡œí† ì½œ ì‹œì‘:**
```powershell
/unit-start
```

**3. ëª©í‘œ ì„ ì–¸:**
```markdown
## U-015: Vision ëª¨ë“ˆ ê¸°ë°˜ êµ¬ì¶•
### 1. ëª©í‘œ
- Florence-2 ëª¨ë¸ì„ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” VisionAnalyzer í´ë˜ìŠ¤ êµ¬í˜„
- ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ìº¡ì…˜ ìƒì„± ê²€ì¦

### ì™„ë£Œ ì¡°ê±´
- [ ] Florence-2 ëª¨ë¸ ë¡œë“œ ì„±ê³µ (<10ì´ˆ)
- [ ] í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì—ì„œ ìº¡ì…˜ ìƒì„± (<1ì´ˆ)
- [ ] ìº¡ì…˜ ê¸¸ì´ 10ì ì´ìƒ, ì˜ë¯¸ ìˆëŠ” ë‚´ìš©
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### Florence-2 ë¬¸ì„œ
- **HuggingFace**: https://huggingface.co/microsoft/Florence-2-large
- **ë…¼ë¬¸**: https://arxiv.org/abs/2311.06242
- **ì˜ˆì œ ì½”ë“œ**: https://huggingface.co/microsoft/Florence-2-large#usage

### ì˜ˆì œ ì½”ë“œ ìŠ¤ë‹ˆí«

```python
# Florence-2 ê¸°ë³¸ ì‚¬ìš©ë²•
from transformers import AutoProcessor, AutoModelForCausalLM
from PIL import Image

# ëª¨ë¸ ë¡œë“œ
model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Florence-2-large",
    trust_remote_code=True
)
processor = AutoProcessor.from_pretrained(
    "microsoft/Florence-2-large",
    trust_remote_code=True
)

# ì´ë¯¸ì§€ ë¶„ì„
image = Image.open("sample.png")
prompt = "<DETAILED_CAPTION>"

inputs = processor(text=prompt, images=image, return_tensors="pt")
generated_ids = model.generate(**inputs, max_new_tokens=1024)
result = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]

print(result)
# ì¶œë ¥ ì˜ˆ: "A fantasy knight character with glowing sword..."
```

---

## ğŸ¯ ì‘ì—… íƒ€ì„ë¼ì¸

### Week 1: Foundation & Integration
```
Day 1 (ì˜¤ëŠ˜):
  [x] Phase 4 ëª…ì„¸ì„œ ì‘ì„± (ì™„ë£Œ)
  [x] ì²´í¬ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ì™„ë£Œ)
  [ ] ì˜ì¡´ì„± ì„¤ì¹˜
  [ ] U-015 ì‹œì‘

Day 2-3:
  [ ] U-015 ì™„ë£Œ (Vision ëª¨ë“ˆ)
  [ ] U-016 ì™„ë£Œ (í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§)

Day 4-5:
  [ ] U-017 ì™„ë£Œ (íŒŒì´í”„ë¼ì¸ í†µí•©)
  [ ] E2E í…ŒìŠ¤íŠ¸

Weekend:
  [ ] ë¬¸ì„œí™” ë° troubleshooting ê¸°ë¡
```

### Week 2: Enhancement & UI
```
Day 1-2:
  [ ] U-018 (ê²€ìƒ‰ í™•ì¥)

Day 3-4:
  [ ] U-019 (GUI í†µí•©)

Day 5:
  [ ] Phase 4 ì™„ë£Œ ê²€ì¦
  [ ] íšŒê³  ì‘ì„±
```

---

## âš¡ ë¹ ë¥¸ ì‹œì‘ ëª…ë ¹ì–´ ìš”ì•½

```powershell
# 1. ì˜ì¡´ì„± ì„¤ì¹˜
python backend/setup/installer.py --install
pip install transformers timm einops

# 2. ë””ë ‰í† ë¦¬ ìƒì„±
mkdir backend\vision

# 3. ì‘ì—… ì‹œì‘
/unit-start

# 4. ì²« ì½”ë“œ ì‘ì„±
# backend/vision/analyzer.py í¸ì§‘ ì‹œì‘
```

---

## ğŸ†˜ ë¬¸ì œ í•´ê²°

### ì„¤ì¹˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ
```powershell
# PyTorch ì¬ì„¤ì¹˜ (CUDA 12.1 ë²„ì „)
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Transformers ë²„ì „ í™•ì¸
pip show transformers
# ë²„ì „ì´ 4.40.0 ë¯¸ë§Œì´ë©´ ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade transformers
```

### GPU ì¸ì‹ ì•ˆ ë  ë•Œ
```python
import torch
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"CUDA Version: {torch.version.cuda}")
print(f"Device Name: {torch.cuda.get_device_name(0)}")
```

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ëŠë¦´ ë•Œ
- HuggingFace ë¯¸ëŸ¬ ì‚¬ìš© ê³ ë ¤
- ëª¨ë¸ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ í›„ ë¡œì»¬ ê²½ë¡œ ì§€ì •

---

**ì¤€ë¹„ ì™„ë£Œ!** ì´ì œ `/unit-start`ë¡œ U-015ë¥¼ ì‹œì‘í•˜ì„¸ìš”.
