# í†µí•© ì•„í‚¤í…ì²˜: PSD ë ˆì´ì–´ ë‹¨ìœ„ ì§€ëŠ¥í˜• ë¶„ì„ ì‹œìŠ¤í…œ

## ğŸ¯ ë¹„ì „ í†µí•©

### ì‚¬ìš©ìì˜ í•µì‹¬ ë¹„ì „
> **"Qwenì€ ì´ë¯¸ì§€ì˜ 'ë‚´ìš©ë¬¼'ì„ í…ìŠ¤íŠ¸ë¡œ ì ì–´ë‘ëŠ” ì„œê¸°ì´ê³ , CLIPì€ ì´ë¯¸ì§€ì˜ 'ì¸ìƒ'ì„ ê¸°ì–µí•˜ëŠ” ëª©ê²©ìì…ë‹ˆë‹¤."**

ì´ ë¹„ì „ì„ ImageParser í”„ë¡œì íŠ¸ì— í†µí•©í•˜ì—¬ **íŒŒì¼ ë‹¨ìœ„ â†’ ë ˆì´ì–´ ë‹¨ìœ„** ë¶„ì„ìœ¼ë¡œ í™•ì¥í•©ë‹ˆë‹¤.

---

## ğŸ—ï¸ ìµœì¢… ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 3-Axis + ë ˆì´ì–´ ë¶„í•´ í†µí•© êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PSD íŒŒì¼ (ì…ë ¥)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 1: Structural Parsing (êµ¬ì¡°ì  ë¶„ì„)                   â”‚
â”‚  - psd-toolsë¡œ ë ˆì´ì–´ íŠ¸ë¦¬ ë¶„í•´                               â”‚
â”‚  - ê° ë ˆì´ì–´ë¥¼ PNGë¡œ ë Œë”ë§                                   â”‚
â”‚  - ì¢Œí‘œ, í¬ê¸°, íƒ€ì…, í°íŠ¸ ì¶”ì¶œ                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2: Latent     â”‚            â”‚  Phase 4: Descriptiveâ”‚
â”‚  (ê°ê°ì  ê²€ìƒ‰)        â”‚            â”‚  (ì§€ëŠ¥í˜• ë¶„ì„)        â”‚
â”‚                      â”‚            â”‚                      â”‚
â”‚  OpenCLIP ViT-L/14   â”‚            â”‚  Vision LM           â”‚
â”‚  - 768ì°¨ì› ë²¡í„°       â”‚            â”‚  (Qwen or Florence)  â”‚
â”‚  - ì‹œê°ì  ìœ ì‚¬ë„      â”‚            â”‚  - OCR í…ìŠ¤íŠ¸        â”‚
â”‚  - "ë¬´ë“œ" ê²€ìƒ‰        â”‚            â”‚  - ìƒì„¸ ìº¡ì…˜         â”‚
â”‚  - 0.01ì´ˆ/query      â”‚            â”‚  - íƒœê·¸ ì¶”ì¶œ         â”‚
â”‚                      â”‚            â”‚  - ì¢Œí‘œ ë¶„ì„         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 3: ChromaDB Storage (í†µí•© ì €ì¥ì†Œ)                     â”‚
â”‚  - ë ˆì´ì–´ ë‹¨ìœ„ë¡œ ì¸ë±ì‹±                                       â”‚
â”‚  - ë²¡í„° + ë©”íƒ€ë°ì´í„° í†µí•©                                     â”‚
â”‚  - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Vector + Keyword + Filter)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š ë°ì´í„° ìŠ¤í‚¤ë§ˆ (ì‚¬ìš©ì ë¹„ì „ ë°˜ì˜)

### ChromaDB ë ˆì´ì–´ ë ˆì½”ë“œ êµ¬ì¡°

```python
{
    # === ê³ ìœ  ì‹ë³„ì ===
    "id": "proj_summer_2026_001_layer_052",

    # === ê²€ìƒ‰ ëŒ€ìƒ ë¬¸ì„œ (Qwen ìº¡ì…˜) ===
    "document": "í•´ë³€ ë°°ê²½ì— ì„¸ì¼ ë¬¸êµ¬ê°€ ì íŒ í”„ë¡œëª¨ì…˜ ë°°ë„ˆ",

    # === ì„ë² ë”© ë²¡í„° (CLIP ìë™ ìƒì„±) ===
    "embedding": [0.12, -0.59, 0.99, ...],  # 768ì°¨ì›

    # === ë©”íƒ€ë°ì´í„° (ê²€ìƒ‰ í•„í„°ë§ìš©) ===
    "metadata": {
        # 1. ì¶œì²˜ ì •ë³´
        "source_file": "C:/Assets/summer_promo.psd",
        "layer_index": 52,
        "layer_name": "Banner_50%_Sale",
        "layer_path": "Group1/Promo/Banner_50%_Sale",

        # 2. ë¬¼ë¦¬/êµ¬ì¡° ì •ë³´ (Python ì¶”ì¶œ)
        "layer_type": "pixel",  # text, pixel, shape, group
        "width": 1200,
        "height": 400,
        "pos_x": 150,
        "pos_y": 300,
        "canvas_width": 1920,
        "canvas_height": 1080,

        # 3. ë¹„ì „ ë¶„ì„ ì •ë³´ (Qwen/Florence ì¶”ì¶œ)
        "ai_caption": "í•´ë³€ ë°°ê²½ì— ì„¸ì¼ ë¬¸êµ¬ê°€ ì íŒ í”„ë¡œëª¨ì…˜ ë°°ë„ˆ",
        "ai_tags": "summer,beach,banner,sale,promotion",
        "ai_style": "minimalist,modern,bright",
        "dominant_color": "#007BFF",
        "color_palette": "#007BFF,#FFFFFF,#FFD700",

        # 4. í…ìŠ¤íŠ¸/OCR (Qwen/Python ì¶”ì¶œ)
        "ocr_text": "SUMMER BIG SALE 50%",
        "font_family": "Helvetica Neue Bold",
        "text_color": "#FFFFFF",

        # 5. ê´€ë¦¬ ì •ë³´
        "user_tags": "",  # ì‚¬ìš©ì ì»¤ìŠ¤í…€ íƒœê·¸
        "project_name": "summer_campaign_2026",
        "status": "untagged",  # untagged, approved, pending, archived
        "created_at": "2026-02-06T13:30:00Z",
        "modified_at": "2026-02-06T13:30:00Z",

        # 6. íŒŒì¼ ë‹¨ìœ„ ì •ë³´ (ê¸°ì¡´ Phase 1-3)
        "file_format": "PSD",
        "file_size_mb": 45.2,
        "layer_count_total": 127,
    }
}
```

---

## ğŸ” ê²€ìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ (í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬)

### 1. ìì—°ì–´ ê²€ìƒ‰ (CLIP ë²¡í„°)
```python
query = "ì‹œì›í•œ ëŠë‚Œì˜ íŒŒë€ìƒ‰ ë²„íŠ¼"
results = collection.query(
    query_texts=[query],
    n_results=20
)
# CLIPì´ ì‹œê°ì  ìœ ì‚¬ë„ë¡œ ê²€ìƒ‰
```

### 2. ì •ë°€ í•„í„°ë§ (ë©”íƒ€ë°ì´í„°)
```python
results = collection.query(
    query_texts=["ë²„íŠ¼"],
    where={
        "$and": [
            {"ocr_text": {"$contains": "50%"}},
            {"width": {"$gte": 500}},
            {"layer_type": {"$eq": "pixel"}},
            {"dominant_color": {"$contains": "blue"}}
        ]
    },
    n_results=10
)
```

### 3. ë³µí•© ê²€ìƒ‰ (AI + ì‚¬ìš©ì íƒœê·¸)
```python
results = collection.query(
    query_texts=["ê³ ì–‘ì´"],
    where={
        "$and": [
            {"ai_tags": {"$contains": "cat"}},
            {"user_tags": {"$contains": "Aí”„ë¡œì íŠ¸"}},
            {"status": {"$eq": "approved"}}
        ]
    }
)
```

### 4. ìœ„ì¹˜ ê¸°ë°˜ ê²€ìƒ‰
```python
# "ì˜¤ë¥¸ìª½ í•˜ë‹¨ ë°°ë„ˆë§Œ ì°¾ê¸°"
results = collection.query(
    query_texts=["ë°°ë„ˆ"],
    where={
        "$and": [
            {"pos_x": {"$gte": 1200}},  # ì˜¤ë¥¸ìª½
            {"pos_y": {"$gte": 700}},   # í•˜ë‹¨
            {"layer_type": {"$ne": "group"}}  # ê·¸ë£¹ ì œì™¸
        ]
    }
)
```

---

## ğŸ–¥ï¸ í™˜ê²½ë³„ ìµœì í™” ì „ëµ

### Windows (RTX 3060 Ti) - í˜„ì¬ í”„ë¡œì íŠ¸
| ì»´í¬ë„ŒíŠ¸ | ëª¨ë¸ | VRAM | ì†ë„ |
|---------|------|------|------|
| **Visual Embedding** | CLIP ViT-L-14 | 2GB | 0.5ì´ˆ/image |
| **Vision Analysis** | Florence-2-large | 2GB | 0.5ì´ˆ/image |
| **Total** | - | ~4GB | ~1ì´ˆ/layer |

**ì¥ì :**
- Florence-2ëŠ” Microsoft ê³µì‹, ì•ˆì •ì 
- Object Detection, OCR í†µí•© ì§€ì›
- Windows ìƒíƒœê³„ì™€ í˜¸í™˜ì„± ìš°ìˆ˜

### MacBook M5 (32GB) - ì‚¬ìš©ì í™˜ê²½
| ì»´í¬ë„ŒíŠ¸ | ëª¨ë¸ | ë©”ëª¨ë¦¬ | ì†ë„ |
|---------|------|--------|------|
| **Visual Embedding** | CLIP ViT-L-14 | 2GB | 0.3ì´ˆ/image (NPU) |
| **Vision Analysis** | Qwen2.5-VL (7B) | 8GB | 0.8ì´ˆ/image (MLX) |
| **Total** | - | ~10GB | ~1ì´ˆ/layer |

**ì¥ì :**
- Qwenì€ ë‹¤êµ­ì–´(ì¤‘/ì˜/í•œ) ê°•ë ¥
- MLX/Ollamaë¡œ NPU ê°€ì†
- í†µí•© ë©”ëª¨ë¦¬ 32GBë¡œ ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

**ê¶Œì¥:**
- ë°°ì¹˜ í¬ê¸°: 32ê°œ (32GB Ã· 10GB â‰ˆ 3ë°°ì¹˜)
- ë³‘ë ¬ ì²˜ë¦¬: 4 workers
- ì˜ˆìƒ ì²˜ë¦¬ëŸ‰: 1000 ë ˆì´ì–´ â†’ 30ë¶„~1ì‹œê°„

---

## ğŸ”„ íŒŒì´í”„ë¼ì¸ í†µí•© (Phase 4 ìˆ˜ì •)

### ê¸°ì¡´ ê³„íš (íŒŒì¼ ë‹¨ìœ„)
```python
# ingest_engine.py (ê¸°ì¡´)
def process_file(file_path):
    meta = parser.parse(file_path)  # íŒŒì¼ ì „ì²´ ë¶„ì„
    vision_result = analyzer.analyze(thumbnail)  # ì¸ë„¤ì¼ 1ì¥ë§Œ
    meta.ai_caption = vision_result["caption"]
    indexer.index_image(file_path, meta)  # íŒŒì¼ 1ê°œ ì¸ë±ì‹±
```

### í™•ì¥ ê³„íš (ë ˆì´ì–´ ë‹¨ìœ„)
```python
# ingest_engine.py (í™•ì¥)
def process_file(file_path):
    # 1. íŒŒì¼ ë‹¨ìœ„ ë¶„ì„ (ê¸°ì¡´)
    file_meta = parser.parse(file_path)

    # 2. ë ˆì´ì–´ ë‹¨ìœ„ ë¶„ì„ (NEW)
    layer_analyzer = LayerVisionAnalyzer()

    for layer in file_meta.layer_tree:
        # ê° ë ˆì´ì–´ë¥¼ PNGë¡œ ë Œë”ë§
        layer_image = render_layer(psd, layer)

        # CLIP + Vision ë¶„ì„
        layer_result = layer_analyzer.analyze(
            image=layer_image,
            context={
                "layer_name": layer.name,
                "layer_type": layer.kind,
                "position": (layer.left, layer.top),
                "size": (layer.width, layer.height)
            }
        )

        # ChromaDBì— ë ˆì´ì–´ ë‹¨ìœ„ë¡œ ì¸ë±ì‹±
        layer_record = {
            "id": f"{file_hash}_{layer.index}",
            "document": layer_result["caption"],
            "metadata": {
                "source_file": str(file_path),
                "layer_index": layer.index,
                "layer_name": layer.name,
                "layer_path": layer.path,
                "layer_type": layer.kind,
                "width": layer.width,
                "height": layer.height,
                "pos_x": layer.left,
                "pos_y": layer.top,
                # Vision ë¶„ì„ ê²°ê³¼
                "ai_caption": layer_result["caption"],
                "ai_tags": ",".join(layer_result["tags"]),
                "ai_style": layer_result.get("style", ""),
                "dominant_color": layer_result.get("color", ""),
                "ocr_text": layer_result.get("ocr", ""),
                # ê´€ë¦¬ ì •ë³´
                "user_tags": "",
                "status": "untagged",
                "created_at": datetime.now().isoformat()
            }
        }

        indexer.index_layer(layer_record)
```

---

## ğŸ“‹ Phase 4 ì¬ì •ì˜ (ë ˆì´ì–´ ë‹¨ìœ„ ë¶„ì„)

### U-015: ë ˆì´ì–´ ë Œë”ë§ ë° ê¸°ë°˜ êµ¬ì¶•
**ëª©í‘œ:**
- PSD ë ˆì´ì–´ë¥¼ ê°œë³„ PNGë¡œ ë Œë”ë§
- LayerVisionAnalyzer í´ë˜ìŠ¤ êµ¬í˜„
- ë ˆì´ì–´ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ

**êµ¬í˜„:**
```python
# backend/vision/layer_renderer.py
def render_layer(psd, layer, output_size=(512, 512)):
    """ë ˆì´ì–´ë¥¼ ë…ë¦½ì ì¸ PNGë¡œ ë Œë”ë§"""
    layer_image = layer.composite()
    if layer_image:
        layer_image.thumbnail(output_size)
        return layer_image
    return None
```

**í…ŒìŠ¤íŠ¸:**
```python
renderer = LayerRenderer()
image = renderer.render_layer(psd, layer)
assert image is not None
assert image.size[0] <= 512
```

---

### U-016: Vision ëª¨ë¸ í†µí•© (í™˜ê²½ë³„)

**Windows (Florence-2):**
```python
from transformers import AutoProcessor, AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Florence-2-large",
    trust_remote_code=True
).to("cuda")

def analyze_layer(image, context):
    prompt = f"<DETAILED_CAPTION> This is a {context['layer_type']} layer"
    inputs = processor(text=prompt, images=image, return_tensors="pt").to("cuda")
    result = model.generate(**inputs, max_new_tokens=256)
    return processor.decode(result[0])
```

**MacBook M5 (Qwen2.5-VL):**
```python
# Ollama API ì‚¬ìš©
import ollama

def analyze_layer(image, context):
    prompt = f"Describe this {context['layer_type']} layer in detail"
    response = ollama.chat(
        model="qwen2.5-vl:7b",
        messages=[{
            'role': 'user',
            'content': prompt,
            'images': [image]
        }]
    )
    return response['message']['content']
```

---

### U-017: ChromaDB ìŠ¤í‚¤ë§ˆ í™•ì¥

**ë ˆì´ì–´ ì»¬ë ‰ì…˜ ìƒì„±:**
```python
# backend/vector/indexer.py
class LayerIndexer:
    def __init__(self):
        self.client = chromadb.PersistentClient(path="chroma_db")
        self.layer_collection = self.client.get_or_create_collection(
            name="layer_library",
            metadata={"description": "PSD layer-level analysis"}
        )

    def index_layer(self, layer_record: Dict[str, Any]):
        """ë ˆì´ì–´ ë‹¨ìœ„ ì¸ë±ì‹±"""
        self.layer_collection.upsert(
            ids=[layer_record["id"]],
            documents=[layer_record["document"]],
            metadatas=[layer_record["metadata"]],
            embeddings=[self._get_embedding(layer_record["image"])]
        )
```

---

### U-018: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„

```python
# backend/vector/searcher.py
class LayerSearcher:
    def search_hybrid(
        self,
        query: str,
        filters: Dict = None,
        top_k: int = 20
    ):
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰:
        1. CLIP ë²¡í„° ê²€ìƒ‰ (70%)
        2. ë©”íƒ€ë°ì´í„° í•„í„°ë§ (ì •ë°€)
        3. í‚¤ì›Œë“œ ë§¤ì¹­ (30%)
        """
        # Vector ê²€ìƒ‰
        results = self.layer_collection.query(
            query_texts=[query],
            where=filters,
            n_results=top_k * 2
        )

        # í‚¤ì›Œë“œ ì¬ìŠ¤ì½”ì–´ë§
        query_words = set(query.lower().split())

        for result in results["metadatas"][0]:
            caption = result.get("ai_caption", "").lower()
            tags = result.get("ai_tags", "").lower()

            keyword_match = len(
                query_words & (set(caption.split()) | set(tags.split(",")))
            ) / len(query_words)

            # í†µí•© ìŠ¤ì½”ì–´
            result["score"] = 0.7 * result["score"] + 0.3 * keyword_match

        return sorted(results, key=lambda x: x["score"], reverse=True)[:top_k]
```

---

### U-019: GUI ë ˆì´ì–´ ë·°ì–´

```jsx
// frontend/src/components/LayerViewer.jsx
export const LayerViewer = ({ psdFile }) => {
  const [layers, setLayers] = useState([]);
  const [selectedLayer, setSelectedLayer] = useState(null);

  useEffect(() => {
    // ë ˆì´ì–´ ëª©ë¡ ë¡œë“œ
    window.electron.readLayers(psdFile).then(setLayers);
  }, [psdFile]);

  return (
    <div className="layer-grid">
      {layers.map(layer => (
        <div key={layer.id} className="layer-card">
          <img src={layer.thumbnail} />
          <div className="layer-info">
            <h4>{layer.name}</h4>
            <p>{layer.ai_caption}</p>
            <div className="tags">
              {layer.ai_tags.split(',').map(tag => (
                <span className="tag">{tag}</span>
              ))}
            </div>
            <div className="meta">
              <span>Size: {layer.width}Ã—{layer.height}</span>
              <span>Pos: ({layer.pos_x}, {layer.pos_y})</span>
              <span>Type: {layer.layer_type}</span>
            </div>
          </div>
        </div>
      ))}
    </div>
  );
};
```

---

## ğŸ¯ ì„±ëŠ¥ ì˜ˆì¸¡

### ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ (1000 ë ˆì´ì–´ ê¸°ì¤€)

| í™˜ê²½ | ëª¨ë¸ | ë°°ì¹˜ í¬ê¸° | ì˜ˆìƒ ì‹œê°„ |
|------|------|----------|----------|
| **Windows RTX 3060 Ti** | Florence-2 | 10 layers | ~50ë¶„ |
| **MacBook M5 32GB** | Qwen2.5-VL | 32 layers | ~30ë¶„ |

**ë³‘ëª© êµ¬ê°„:**
1. ë ˆì´ì–´ ë Œë”ë§: ~0.1ì´ˆ/layer (CPU)
2. Vision ë¶„ì„: ~0.8ì´ˆ/layer (GPU/NPU)
3. ë²¡í„° ì¸ë±ì‹±: ~0.05ì´ˆ/layer (DB)

**ìµœì í™” ì „ëµ:**
- ë©€í‹°í”„ë¡œì„¸ì‹±: ë Œë”ë§ 4 workers
- ë°°ì¹˜ ì²˜ë¦¬: Vision ë¶„ì„ ë³‘ë ¬í™”
- ìºì‹±: ë™ì¼ ë ˆì´ì–´ ì¬ë¶„ì„ ë°©ì§€

---

## ğŸ“š ìµœì¢… ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
ImageParser/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ vision/
â”‚   â”‚   â”œâ”€â”€ layer_renderer.py      # ë ˆì´ì–´ PNG ë Œë”ë§
â”‚   â”‚   â”œâ”€â”€ layer_analyzer.py      # ë ˆì´ì–´ ë‹¨ìœ„ Vision ë¶„ì„
â”‚   â”‚   â”œâ”€â”€ analyzer_florence.py   # Windowsìš© (Florence-2)
â”‚   â”‚   â”œâ”€â”€ analyzer_qwen.py       # Macìš© (Qwen2.5-VL)
â”‚   â”‚   â””â”€â”€ prompt_templates.py
â”‚   â”œâ”€â”€ vector/
â”‚   â”‚   â”œâ”€â”€ layer_indexer.py       # ë ˆì´ì–´ ë‹¨ìœ„ ì¸ë±ì‹±
â”‚   â”‚   â””â”€â”€ layer_searcher.py      # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
â”‚   â””â”€â”€ pipeline/
â”‚       â””â”€â”€ ingest_engine.py       # íŒŒì¼ + ë ˆì´ì–´ í†µí•© íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ chroma_db/
â”‚   â”œâ”€â”€ file_library/              # ê¸°ì¡´ íŒŒì¼ ë‹¨ìœ„
â”‚   â””â”€â”€ layer_library/             # NEW ë ˆì´ì–´ ë‹¨ìœ„
â””â”€â”€ docs/
    â”œâ”€â”€ unified_architecture.md    # ì´ ë¬¸ì„œ
    â””â”€â”€ layer_schema_spec.md       # ë ˆì´ì–´ ìŠ¤í‚¤ë§ˆ ìƒì„¸
```

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

### 1. ì˜ì¡´ì„± ì„¤ì¹˜
```powershell
# Windows
python backend/setup/installer.py --install
pip install transformers timm einops

# MacBook M5
brew install ollama
ollama pull qwen2.5-vl:7b
pip install ollama chromadb sentence-transformers
```

### 2. ë ˆì´ì–´ ë Œë”ë§ í…ŒìŠ¤íŠ¸
```python
python -c "
from backend.vision.layer_renderer import LayerRenderer
renderer = LayerRenderer()
layers = renderer.render_all_layers('test.psd')
print(f'Rendered {len(layers)} layers')
"
```

### 3. Phase 4 ì‹œì‘
```powershell
/unit-start  # U-015: ë ˆì´ì–´ ë Œë”ë§ ë° ê¸°ë°˜ êµ¬ì¶•
```

---

## ğŸ’¡ í•µì‹¬ ìš”ì•½

**ì´ ì‹œìŠ¤í…œì˜ ë³¸ì§ˆ:**
> "PSD íŒŒì¼ì„ ì›ì(ë ˆì´ì–´) ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ê³ , ê° ì›ìì— Qwen(ì„œê¸°)ê³¼ CLIP(ëª©ê²©ì)ì˜ ê¸°ë¡ì„ ëª¨ë‘ ìƒˆê¸´ ë’¤, ChromaDBë¼ëŠ” ë„ì„œê´€ì— ë³´ê´€í•˜ì—¬ ì–´ë–¤ ì§ˆë¬¸ì—ë„ ì¦‰ì‹œ ë‹µí•  ìˆ˜ ìˆê²Œ ë§Œë“œëŠ” ê²ƒ"

**3ê°€ì§€ í•µì‹¬ ê°€ì¹˜:**
1. **ë ˆì´ì–´ ë‹¨ìœ„ ë¶„ì„**: íŒŒì¼ì´ ì•„ë‹Œ ë ˆì´ì–´ë³„ ì„¸ë°€í•œ ì¸ë±ì‹±
2. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: ê°ê°(CLIP) + ì§€ì„±(Qwen) + í•„í„°(ë©”íƒ€ë°ì´í„°)
3. **í™˜ê²½ ìµœì í™”**: Windows(Florence) / Mac(Qwen) ëª¨ë‘ ì§€ì›

---

**ì‘ì„±ì¼**: 2026-02-06
**í†µí•© ë²„ì „**: v1.0
**ë‹¤ìŒ ë¬¸ì„œ**: `layer_implementation_guide.md`
