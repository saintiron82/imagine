# ImageParser 개발명세서 v3 (Final)

**작성일**: 2026-02-08
**최종 개정일**: 2026-02-08 (v3 Final — P2 S축 완료 반영)
**기준**: Phase 4 진행중, 논의 기반 개선 로드맵
**목적**: 검색 적중률 30~40% → 85~95% 달성

---

## 변경 이력

| 버전 | 주요 변경 | 사유 |
|------|----------|------|
| v1 | 초안 작성 | Phase 4 계획 수립 |
| v2 | Vision → Qwen3-VL-8B, V축 → SigLIP 2, S축 → Qwen3-Embedding, DB 이중저장, 3단계 JSON Repair | 모델 리서치 반영 |
| v3 | 실제 구현 상태 반영, P0/P1 완료 확인, 미구현 항목 정리, config/styles 제거 | 문서-코드 일치화 |
| **v3.1** | P0 100% 완료 (99파일 처리), P2 S축 구현 완료, 3축 검색 검증 | P2 완료 반영 |

---

## 1. 현재 상태 진단

### 1.1 핵심 병목 (v3 이전)

```
"골목길" 검색 실패 분석:
  └─ CLIP이 스타일라이즈된 일러스트를 시각적으로 매칭 못함
  └─ FTS5가 "골목길"/"alley" 키워드를 찾을 수 없음
  └─ ai_caption에 "alley"가 포함되지 않음
  └─ Qwen2.5-VL 범용 프롬프트가 "urban background" 수준만 생성
  └─ ★ 근본 원인: Vision 프롬프트 구조 부재
```

### 1.2 v3 이전 검색 적중률

| 쿼리 유형 | 적중률 | 원인 |
|-----------|--------|------|
| 실사 사진 (CLIP 강점) | 70~85% | CLIP이 실사에 최적화 |
| 일러스트/게임 에셋 (CLIP 약점) | 30~50% | 도메인 불일치 |
| 씬 기반 ("골목길", "숲") | 20~40% | 캡션 부실 → FTS5 무용 |
| 복합 조건 ("비오는 밤 배경") | 10~20% | 구조화 메타데이터 부재 |
| UI/아이콘 검색 | 20~30% | 분류 체계 없음 |

### 1.3 Triaxis 검색의 한계 (v3 이전)

| 축 | 상태 | 문제 |
|----|------|------|
| V축 (CLIP ViT-L/14) | ImageNet 75% 수준의 구 모델 | 일러스트 도메인에서 정확도 떨어짐 |
| FTS5 | ai_caption 품질에 100% 종속 | 범용 캡션이라 키워드 매칭 불안정 |
| Filter | format, user_category, rating만 | image_type 자동 분류 없음 |
| RRF | V축 편중 | FTS5/Filter가 약해 사실상 단축 검색 |

---

## 2. 개선 로드맵 (우선순위순)

### 진행 상태 요약

| 순위 | 작업 | 예상 효과 | 상태 |
|------|------|----------|------|
| **P0** | 2-Stage Vision Pipeline + DB 스키마 확장 | +30~50%p 적중률 | **완료** (99파일 처리, image_type 100% 커버) |
| **P1** | V축 모델 교체 (SigLIP 2 So400m) | +5~10%p 적중률 | **완료** (마이그레이션+재인덱싱 완료) |
| **P2** | S축 추가 (Qwen3-Embedding-0.6B) | +10~15%p 적중률 | **완료** (99파일 S축 임베딩, 3축 RRF 검증) |
| **P2+** | Auto-Weighted RRF | +2~5%p 적중률 | **완료** (가중치 프리셋 A, LLM 하드 필터 폐기) |
| **P3** | 인프라 개선 | 안정성, 성능 | 미구현 |
| **P4** | 서버형 전환 준비 | 확장성 | 미구현 |

### 개발 진행 체크리스트

#### P0: 2-Stage Vision Pipeline — 완료
- [x] Qwen3-VL-8B 모델 선정 및 Ollama 설치
- [x] Stage 1 분류 프롬프트 작성 (11개 image_type)
- [x] Stage 2 타입별 전용 프롬프트 작성 (character, background, ui_element, item, icon, texture, effect, logo, photo, illustration, other)
- [x] JSON Schema 정의 (`vision/schemas.py`)
- [x] 3단계 JSON Repair 로직 (`vision/repair.py`)
- [x] Ollama 어댑터 구현 (`vision/ollama_adapter.py`)
- [x] DB 스키마 확장 (15개 컬럼 추가)
- [x] FTS5 16컬럼 확장
- [x] 인제스트 파이프라인 통합 (`ingest_engine.py`)
- [x] 검색 엔진 필터 확장 (`sqlite_search.py`)
- [x] 프론트엔드 필터 UI (image_type/art_style 드롭다운)
- [x] config.yaml vision 섹션 설정
- [x] 99파일 전체 Vision 재처리 (image_type NULL = 0)
- [x] 분포 검증: illustration(52), photo(41), background(5), texture(1)

#### P1: V축 SigLIP 2 교체 — 완료
- [x] SigLIP 2 So400m 모델 선정 (Apache 2.0, 109언어)
- [x] SigLIP2Encoder 구현 (`vector/siglip2_encoder.py`)
- [x] AutoImageProcessor + GemmaTokenizerFast 분리 로드
- [x] fp16 추론 + L2 정규화
- [x] DB 마이그레이션 768→1152차원 (`migrations/v3_p1_vec.py`)
- [x] 전체 재인덱싱 (`reindex_v3.py --embedding-only`)
- [x] 한국어 검증: "야경" → yakei.psd 정확 매칭

#### P2: S축 텍스트 임베딩 — 완료
- [x] Qwen3-Embedding-0.6B 모델 선정 (Apache 2.0, 1024차원)
- [x] Ollama 모델 설치 (`ollama pull qwen3-embedding:0.6b`)
- [x] EmbeddingProvider ABC + OllamaEmbeddingProvider 구현 (`vector/text_embedding.py`)
- [x] build_document_text() 함수 (caption+tags → 문서 텍스트)
- [x] vec_text 테이블 마이그레이션 (`migrations/v3_p2_text_vec.py`)
- [x] sqlite_schema.sql에 vec_text 정의 추가
- [x] 인제스트 파이프라인 S축 통합 (`ingest_engine.py`)
- [x] text_vector_search() 구현 (`sqlite_search.py`)
- [x] _rrf_merge_multi() N축 일반화 RRF 병합
- [x] triaxis_search() 3축 통합 (V+T+F)
- [x] config.yaml embedding.text 섹션 활성화
- [x] reindex_v3.py --text-embedding 모드 추가
- [x] 99파일 전체 S축 리인덱싱 (avg 2.23s/file)
- [x] 3축 검색 검증 (영어+한국어, S=0.73 vs V=0.05)

#### P2+: Auto-Weighted RRF — 완료
- [x] 쿼리 유형 분석기 확장 (`query_decomposer.py`) — query_type 4종 (visual/keyword/semantic/balanced)
- [x] QueryDecomposer Chat API 전환 + Qwen3 thinking 억제 (100s → 3s)
- [x] 가중치 전략 모듈 신규 생성 (`search/rrf.py`) — WEIGHT_PRESETS + 재분배 로직
- [x] weighted_rrf 함수 구현 — `_rrf_merge_multi(weights=...)` 파라미터 추가
- [x] sqlite_search.py에 auto-weight 호출 통합 — `triaxis_search` → `get_weights` → `_rrf_merge_multi`
- [x] config.yaml `search.rrf.auto_weight` 설정 추가 — `auto_weight: true` 활성화
- [x] 쿼리 유형별 가중치 검증 (visual/keyword/semantic/balanced)
- [x] **LLM 하드 필터 폐기** — 구조화 필드(scene_type 등) AND 게이트가 결과 100% 삭제 문제 발견 및 해결
- [x] 4종 프리셋(A~D) 비교 실험 → A(0.50/0.30/0.20) 채택

#### P3: 인프라 개선 — 미구현
- [ ] FastAPI 서버 전환 (Python subprocess → long-running)
- [ ] 모델 상주로 검색 지연 200ms → ~10ms
- [ ] 처리 큐 영속성 (SQLite `processing_queue` 테이블)
- [ ] 크래시 시 미완료 작업 자동 재개
- [ ] MetadataModal 컴포넌트 분리 (SearchPanel/FileGrid 중복 제거)

#### P4: 서버형 전환 — 미구현
- [ ] 파일 경로 추상화 적용 (`storage_root` + `relative_path` 활용)
- [ ] 임베딩 버전 관리 활용 (`embedding_model`, `embedding_version`)
- [ ] PostgreSQL + pgvector 마이그레이션
- [ ] 멀티테넌시 (`user_id` 컬럼)
- [ ] 오브젝트 스토리지 전환 (S3/MinIO)
- [ ] 인증/권한 레이어
- [ ] 태스크 큐 (Celery/Redis)

---

### 모델 스택 (v3 확정)

```
┌──────────────────────────────────────────────────────────┐
│  Ingestion Pipeline                                       │
│                                                           │
│  Image ──→ Qwen3-VL-8B (2-Stage: 분류 → 구조화 분석)      │
│         ──→ SigLIP 2 So400m → Vector_A (V축 1152차원)     │
│         ──→ Caption → Qwen3-Embedding-0.6B → Vector_B ✅   │
│         ──→ SQLite (FTS5 + sqlite-vec)                    │
│                                                           │
├──────────────────────────────────────────────────────────┤
│  Search Pipeline                                          │
│                                                           │
│  Query ──→ QueryDecomposer (Flags: Visual/Context/Keyword)│
│        ──→ SigLIP 2: V축 시각 유사도                       │
│        ──→ Qwen3-Embedding: S축 의미 유사도 ✅              │
│        ──→ FTS5: M축 키워드 + 구조화 필터                   │
│        ──→ 3-axis RRF → Results (Auto-Weighted: P2+)      │
└──────────────────────────────────────────────────────────┘
```

### VRAM 버짓

| 모델 | 용도 | VRAM | 상주 시점 |
|------|------|------|----------|
| Qwen3-VL-8B | 인제스트 (캡션) | ~6GB | 인제스트 중만 |
| SigLIP 2 So400m | V축 임베딩 | ~0.8GB | 항상 |
| Qwen3-Embedding-0.6B | S축 임베딩 | ~0.4GB | 항상 ✅ |
| **검색 시 합계** | | **~1.2GB** | |
| **인제스트 시 합계** | | **~7.2GB** | |

---

## 3. [P0] 2-Stage Vision Pipeline — **완료**

### 3.1 개요

단일 범용 프롬프트를 **2단계 분류-분석 파이프라인**으로 교체.
모델: **Qwen3-VL-8B** (Ollama: `qwen3-vl:8b`)

```
이미지 ──→ [Stage 1: 분류] ──→ image_type 결정
                                    │
                    ┌───────────────┼───────────────┬───────────────┐
                    ▼               ▼               ▼               ▼
              "character"     "background"      "ui_element"     "item"
                    │               │               │               │
                    ▼               ▼               ▼               ▼
              [Stage 2]       [Stage 2]        [Stage 2]       [Stage 2]
              캐릭터 전용     배경 전용         UI 전용         아이템 전용
              프롬프트        프롬프트          프롬프트         프롬프트
```

### 3.2 Qwen3-VL-8B 선정 사유

| 항목 | Qwen2.5-VL:7b | Qwen3-VL-8B |
|------|---------------|-------------|
| Ollama 크기 | ~5GB | ~6.1GB |
| 컨텍스트 | 128K | **256K** |
| 구조화 출력 (JSON) | 자주 깨짐 | **대폭 개선** |
| OCR | 중간 | **LLM 수준** |
| 공간 인식 | 기본 | **2D/3D 그라운딩** |

### 3.3 구현 파일 구조

```
backend/vision/
  ├── prompts.py          # 프롬프트 템플릿 (STAGE1_PROMPT, STAGE2_PROMPTS)
  ├── schemas.py          # JSON Schema 정의 (11개 image_type)
  ├── ollama_adapter.py   # Ollama 호출 + 2-Stage 파이프라인
  └── repair.py           # 3단계 JSON Repair 로직
```

> **참고**: v2에서 계획했던 `config/styles/default.yaml` YAML 기반 프롬프트 관리와 `style_builder.py`는 구현하지 않았음. 현재 `prompts.py`에서 코드 내 직접 정의 방식으로 충분히 동작하며, 필요시 향후 외부 설정으로 전환 가능.

### 3.4 Stage 1: 이미지 분류

**목적**: 이미지 타입을 빠르게 판별 (1~2초)

```json
{
  "image_type": "ONE OF: character, background, ui_element, item, icon, texture, effect, logo, photo, illustration, other",
  "confidence": "ONE OF: high, medium, low"
}
```

**image_type 정의:**

| Type | 설명 | 예시 |
|------|------|------|
| `character` | 인물, 몬스터, 동물 등 캐릭터 | 영웅, 보스, NPC, 초상화 |
| `background` | 배경, 환경, 풍경 | 숲, 던전, 마을, 하늘 |
| `ui_element` | UI 컴포넌트 | 버튼, HUD, 인벤토리, 메뉴 |
| `item` | 아이템, 오브젝트 | 무기, 포션, 갑옷, 재료 |
| `icon` | 아이콘, 심볼 | 스킬 아이콘, 상태 아이콘 |
| `texture` | 텍스처, 패턴 | 바닥, 벽, 천 |
| `effect` | 이펙트, 파티클 | 폭발, 마법진, 불꽃 |
| `logo` | 로고, 타이틀 | 게임 로고, 브랜드 |
| `photo` | 실사 사진 | 참고 자료 |
| `illustration` | 범용 일러스트 | 분류 불가한 일러스트 |
| `other` | 기타 | 위 어디에도 해당 없음 |

### 3.5 Stage 2: 타입별 전용 스키마

#### 3.5.1 character (캐릭터)

```json
{
  "character_type": "ONE OF: human, monster, animal, robot, fantasy_creature, chibi, portrait, full_body, bust",
  "gender_presentation": "ONE OF: masculine, feminine, androgynous, non_human, ambiguous",
  "age_range": "ONE OF: child, teen, young_adult, adult, elderly, ageless",
  "pose": "ONE OF: standing, sitting, action, portrait, dynamic, idle",
  "equipment": ["list: sword, staff, bow, gun, shield, armor, robe, hat, wings, etc."],
  "emotion": "ONE OF: neutral, happy, angry, sad, determined, mysterious, scared, smiling",
  "art_style": "...", "color_palette": "...", "caption": "...", "tags": ["..."]
}
```

#### 3.5.2 background (배경)

```json
{
  "scene_type": "ONE OF: alley, forest, dungeon, castle, village, city_street, interior_room, interior_hall, sky, ocean, mountain, battlefield, ruins, cave, road, bridge, garden, marketplace, temple, graveyard, rooftop, underground, harbor, desert, tundra, swamp, floating_island, space, library, tavern, throne_room, prison, other",
  "time_of_day": "ONE OF: dawn, morning, noon, afternoon, sunset, dusk, night, ambiguous",
  "weather": "ONE OF: clear, cloudy, rain, snow, fog, storm, wind, none",
  "season": "ONE OF: spring, summer, autumn, winter, ambiguous",
  "mood": "ONE OF: peaceful, tense, mysterious, epic, lonely, cheerful, ominous, romantic, desolate",
  "architecture_style": "ONE OF: medieval, modern, futuristic, asian, arabic, ruins, fantasy, industrial, rural, victorian, gothic, none",
  "lighting": "ONE OF: bright, dim, dramatic, neon, candlelight, moonlight, sunlight, magical_glow, underwater",
  "depth": "ONE OF: close, mid, panoramic, bird_eye",
  "art_style": "...", "color_palette": "...", "caption": "...", "tags": ["..."]
}
```

#### 3.5.3 ui_element (UI)

```json
{
  "ui_type": "ONE OF: button, panel, frame, hud, dialog_box, inventory, minimap, health_bar, menu, popup, tooltip, loading_screen, title_screen, scoreboard, chat_box, other",
  "ui_style": "ONE OF: flat, skeuomorphic, glassmorphism, pixel, fantasy_ornate, sci_fi, minimal, hand_drawn",
  "color_scheme": "ONE OF: light, dark, colorful, monochrome, themed",
  "has_text": "true / false",
  "text_content": "extracted visible text or empty string",
  "interactive_elements": ["list: button, slider, checkbox, toggle, input_field, dropdown, tab, etc."],
  "platform": "ONE OF: mobile, desktop, console, web, universal",
  "art_style": "...", "caption": "...", "tags": ["..."]
}
```

#### 3.5.4 item (아이템)

```json
{
  "item_type": "ONE OF: weapon, armor, potion, food, tool, accessory, material, currency, key_item, vehicle, furniture, plant, gem, scroll, container, clothing, other",
  "item_subtype": "free text, e.g. 'longsword', 'healing potion', 'gold coin'",
  "rarity_feel": "ONE OF: common, uncommon, rare, epic, legendary",
  "material": "ONE OF: metal, wood, leather, cloth, crystal, bone, stone, magical, organic, mechanical, glass, paper",
  "has_transparency": "true / false",
  "view_angle": "ONE OF: front, side, isometric, top_down, perspective, three_quarter",
  "art_style": "...", "color_palette": "...", "caption": "...", "tags": ["..."]
}
```

#### 3.5.5 icon (아이콘)

```json
{
  "icon_category": "ONE OF: skill, status_effect, buff, debuff, element, class, navigation, social, settings, currency, notification, emote, other",
  "icon_shape": "ONE OF: square, circle, diamond, hexagon, shield, irregular",
  "has_border": "true / false",
  "has_text": "true / false",
  "text_content": "extracted text or empty string",
  "color_palette": "...", "art_style": "...", "caption": "...", "tags": ["..."]
}
```

#### 3.5.6 texture (텍스처)

```json
{
  "texture_type": "ONE OF: ground, wall, floor, ceiling, fabric, metal, wood, stone, water, vegetation, skin, magical, sci_fi, other",
  "tileable": "ONE OF: yes, no, likely",
  "surface": "ONE OF: rough, smooth, bumpy, cracked, mossy, wet, dusty, polished",
  "color_palette": "...", "caption": "...", "tags": ["..."]
}
```

#### 3.5.7 effect (이펙트)

```json
{
  "effect_type": "ONE OF: explosion, fire, ice, lightning, magic_circle, smoke, sparkle, aura, slash, projectile, heal, poison, shield, portal, weather, water_splash, other",
  "has_transparency": "true / false",
  "animation_feel": "ONE OF: static, loopable, burst, sustained",
  "intensity": "ONE OF: subtle, moderate, intense",
  "color_palette": "...", "caption": "...", "tags": ["..."]
}
```

#### 3.5.8 기타 타입 (logo, photo, illustration, other)

```json
{
  "subject": "free text - what the image depicts",
  "art_style": "...", "color_palette": "...",
  "mood": "ONE OF: peaceful, tense, mysterious, epic, cheerful, neutral",
  "has_text": "true / false",
  "text_content": "extracted text or empty string",
  "caption": "...", "tags": ["..."]
}
```

### 3.6 3단계 JSON Repair (`repair.py`)

1. **Tier 1:** `json.loads` 직접 파싱
2. **Tier 2:** `_repair_common_errors` (Markdown 코드블록 제거, 후행 쉼표, 닫히지 않은 괄호, 작은따옴표→큰따옴표)
3. **Tier 3:** Regex 개별 필드 추출 (최후의 수단)
- **최소 보장:** `image_type="other"`, `caption=raw_text[:500]`

### 3.7 DB 스키마 확장 — **완료**

```sql
-- 경로 추상화 (POSIX 정규화)
ALTER TABLE files ADD COLUMN storage_root TEXT;
ALTER TABLE files ADD COLUMN relative_path TEXT;

-- 공통 구조화 필드 (필터/인덱스용)
ALTER TABLE files ADD COLUMN image_type TEXT;
ALTER TABLE files ADD COLUMN art_style TEXT;
ALTER TABLE files ADD COLUMN color_palette TEXT;

-- 타입별 핵심 필드
ALTER TABLE files ADD COLUMN scene_type TEXT;      -- 배경 전용
ALTER TABLE files ADD COLUMN time_of_day TEXT;     -- 배경 전용
ALTER TABLE files ADD COLUMN weather TEXT;         -- 배경 전용
ALTER TABLE files ADD COLUMN character_type TEXT;  -- 캐릭터 전용
ALTER TABLE files ADD COLUMN item_type TEXT;       -- 아이템 전용
ALTER TABLE files ADD COLUMN ui_type TEXT;         -- UI 전용

-- Stage 2 JSON 원본 (NoSQL 유연성)
ALTER TABLE files ADD COLUMN structured_meta TEXT;

-- 임베딩 버전 관리
ALTER TABLE files ADD COLUMN embedding_model TEXT DEFAULT 'clip-ViT-L-14';
ALTER TABLE files ADD COLUMN embedding_version INTEGER DEFAULT 1;

-- 인덱스
CREATE INDEX idx_image_type ON files(image_type);
CREATE INDEX idx_art_style ON files(art_style);
CREATE INDEX idx_scene_type ON files(scene_type);
CREATE INDEX idx_relative_path ON files(relative_path);
```

### 3.8 Ollama 배치 처리 전략 — **완료**

- `keep_alive="5m"` 배치 중 모델 유지
- 배치 완료 후 `_unload_model()` 호출
- `config.yaml`에서 `vision.keep_alive`, `vision.temperature`, `vision.max_retries` 설정

### 3.9 인제스트 파이프라인 통합 — **완료**

**위치:** `backend/pipeline/ingest_engine.py`

- Stage 1 분류 → `image_type` 결정
- Stage 2 분석 → 타입별 구조화 JSON 생성
- 이중 저장: `structured_meta` (JSON 원본) + 개별 컬럼 (인덱스용)
- 경로 POSIX 정규화 (`replace('\\', '/')`)

### 3.10 검색 엔진 필터 확장 — **완료**

**위치:** `backend/search/sqlite_search.py`

- `image_type`, `art_style` 필터 지원
- 프론트엔드에서 드롭다운 UI로 필터 전달

### 3.11 프론트엔드 변경 — **완료**

- `SearchPanel.jsx`: image_type/art_style 드롭다운 필터, 결과 카드에 image_type 배지
- `main.cjs`: IPC 핸들러에서 필터 파라미터 전달

### 3.12 config.yaml (현재 상태)

```yaml
vision:
  model: "qwen3-vl:8b"
  keep_alive: "5m"
  temperature: 0.1
  max_retries: 2
  ollama_host: "http://localhost:11434"

search:
  rrf:
    k: 60

embedding:
  visual:
    model: "google/siglip2-so400m-patch14-384"
    dimensions: 1152
  text:
    enabled: true
    model: "qwen3-embedding:0.6b"
    dimensions: 1024
    instruction_prefix: ""

storage:
  path_style: "posix"
```

### 3.13 P0 잔여 작업 — **완료**

- [x] 99파일 전체 Vision 재처리 완료 (image_type NULL = 0)
- [x] 분포: illustration(52), photo(41), background(5), texture(1)
- [x] 프론트엔드 필터 동작 확인

---

## 4. [P1] V축 모델 교체 (SigLIP 2) — **완료**

### 4.1 교체 내용

| 항목 | 이전 | 현재 |
|------|------|------|
| 모델 | CLIP ViT-L/14 | **SigLIP 2 So400m** |
| 차원 | 768 | **1152** |
| 라이선스 | MIT | **Apache 2.0** |
| 다국어 | 영어 중심 | **109개 언어** (Gemma 토크나이저) |
| ImageNet | 75% | **85.0%** |
| VRAM | ~1.5GB | **~0.8GB** |
| 해상도 | 224 고정 | **384 (NaFlex 가변)** |

### 4.2 선정 사유

1. **Apache 2.0**: 상업 전환 시 무제약 (Jina CLIP v2 CC-BY-NC 제외)
2. **109개 언어**: Gemma 토크나이저 (256K vocab), 한국어 최상급
3. **NaFlex**: 게임 에셋의 다양한 종횡비를 네이티브 처리
4. **경량**: 400M 파라미터, ~0.8GB VRAM
5. **85% ImageNet**: CLIP ViT-L의 75%에서 10%p 향상

### 4.3 구현 파일

**위치:** `backend/vector/siglip2_encoder.py`

```python
class SigLIP2Encoder:
    """Lazy-loaded SigLIP 2 encoder for image and text embeddings."""

    def __init__(self, model_name=None):
        # config.yaml에서 모델명/차원 로드
        self.model_name = model_name or cfg.get("embedding.visual.model", "google/siglip2-so400m-patch14-384")
        self._dimensions = cfg.get("embedding.visual.dimensions", 1152)

    def _load(self):
        # AutoModel + AutoImageProcessor + GemmaTokenizerFast 분리 로드
        # local_files_only=True 시도 → OSError 시 HuggingFace 다운로드

    def encode_image(self, image: Image) -> np.ndarray:  # (1152,) L2-normalized
    def encode_text(self, text: str) -> np.ndarray:      # (1152,) L2-normalized
```

**주요 기술 노트:**
- `transformers` 라이브러리 직접 사용 (sentence-transformers 미사용)
- `AutoProcessor` 대신 `AutoImageProcessor` + `GemmaTokenizerFast` 분리 (transformers 5.x 토크나이저 매핑 버그 회피)
- Forward pass: `model(**img_inputs, **txt_inputs)` → `outputs.image_embeds` / `outputs.text_embeds`
- fp16 추론, L2 정규화 적용

### 4.4 DB 마이그레이션 — **완료**

**스크립트:** `backend/db/migrations/v3_p1_vec.py`

- `vec_files` 가상 테이블 재생성 (768차원 → 1152차원)
- 기존 벡터 데이터 삭제 → 재인덱싱 필요
- `embedding_model` → `'google/siglip2-so400m-patch14-384'`
- `embedding_version` → `+1`

### 4.5 재인덱싱 — **완료**

```bash
python tools/reindex_v3.py --embedding-only
# 결과: 19/20 성공 (1개 썸네일 없는 파일 제외)
```

### 4.6 검증 결과

- 한국어 "야경" → `#9_yakei.psd` (夜景) 정확 매칭 — 다국어 동작 확인
- 유사도 스코어: 0.03~0.07 (CLIP 대비 낮지만 랭킹은 정확)
  - SigLIP 2는 sigmoid 기반이라 절대 스코어가 낮은 것은 정상

---

## 5. [P2] S축 추가 (텍스트 임베딩) — **완료**

### 5.1 개요

V축(시각 유사도)과 **독립적인** S축(텍스트 의미 유사도)을 추가.
AI Vision 캡션/태그를 전용 텍스트 모델로 인코딩하여 별도 벡터 검색.

### 5.2 선정 모델: Qwen3-Embedding-0.6B

| 기준 | MiniLM (v1 후보) | Jina v3 (v1 대안) | **Qwen3-Embedding-0.6B (확정)** |
|------|-----------------|------------------|-------------------------------|
| 컨텍스트 | 128 토큰 | 8,192 | **32,768** |
| 다국어 | 50+ | 89 | **100+** |
| 한국어 | 중간 | 상위 | **최상위** |
| Ollama 지원 | ❌ | ❌ | **✅ 네이티브** |
| 라이선스 | Apache 2.0 | CC-BY-NC | **Apache 2.0** |
| VRAM | ~0.4GB | ~1.2GB | **~0.4GB** |
| 최대 차원 | 384 | 1024 | **1024 (MRL)** |

**선정 사유:**
1. 128토큰 → 32K토큰: Qwen3-VL의 긴 캡션을 통째로 처리 가능
2. `ollama embed` API로 호출 — 별도 Python 라이브러리 불필요
3. Vision(Qwen3-VL) + Embedding(Qwen3-Embedding) = 같은 토크나이저 계열
4. Apache 2.0, 100+ 언어

### 5.3 구현 파일 구조 — **완료**

```
backend/vector/text_embedding.py     # EmbeddingProvider ABC + OllamaEmbeddingProvider
backend/db/migrations/v3_p2_text_vec.py  # vec_text 마이그레이션
backend/db/sqlite_schema.sql         # vec_text 테이블 정의 추가
backend/pipeline/ingest_engine.py    # 인제스트 시 S축 자동 생성
backend/search/sqlite_search.py      # S축 검색 + 3축 RRF 병합
config.yaml                          # embedding.text 섹션 활성화
tools/reindex_v3.py                  # --text-embedding 모드 추가
```

#### 5.3.1 EmbeddingProvider (Adapter Pattern)

**파일:** `backend/vector/text_embedding.py`

```python
class EmbeddingProvider(ABC):
    def encode(self, text: str, is_query: bool = False) -> np.ndarray: ...
    def encode_batch(self, texts: list[str], is_query: bool = False) -> list[np.ndarray]: ...

class OllamaEmbeddingProvider(EmbeddingProvider):
    # Ollama /api/embed 엔드포인트 사용
    # config.yaml에서 모델명, 차원, instruction_prefix 로드
    # L2 정규화 적용

def build_document_text(caption: str, tags: list) -> str:
    # ai_caption + ai_tags → 임베딩용 문서 텍스트 조합

def get_text_embedding_provider() -> EmbeddingProvider:
    # 싱글톤 팩토리
```

#### 5.3.2 DB 스키마

```sql
-- vec_text 가상 테이블 (1024차원 텍스트 임베딩)
CREATE VIRTUAL TABLE vec_text USING vec0(
    file_id INTEGER PRIMARY KEY,
    embedding FLOAT[1024]
);
```

#### 5.3.3 인제스트 파이프라인 통합

- `ingest_engine.py` STEP 4/4에서 V축 저장 직후 S축 생성
- `build_document_text(caption, tags)` → `provider.encode()` → `vec_text INSERT`
- `embedding.text.enabled` 설정으로 on/off 제어

#### 5.3.4 검색 엔진 확장

- `text_vector_search()`: `vec_text` 코사인 유사도 검색
- `_rrf_merge_multi()`: N개 축 일반화 RRF 병합
- `triaxis_search()`: V + T + F 3축 통합, diagnostic에 `text_vec_results` 추가
- `text_search_enabled` 프로퍼티: `vec_text` 데이터 존재 시 자동 활성화

#### 5.3.5 재인덱싱

```bash
# S축 리인덱싱
python tools/reindex_v3.py --text-embedding

# 전체 리인덱싱 (Vision + V축 + S축)
python tools/reindex_v3.py --all
```

### 5.4 리인덱싱 결과 — **완료**

```
S-axis reindex: 99/99 succeeded — total 220.5s (avg 2.23s/file)
vec_text entries: 99 (100% coverage)
```

### 5.5 검증 결과

#### 영어 쿼리: "fantasy character with sword"
```
3-axis Search:
  V-axis: 10  S-axis: 10  M-axis: 10
  RRF merged: 28 (axes: 3)
```

#### 한국어 쿼리: "야경"
```
3-axis Search:
  V-axis: 10  S-axis: 10  M-axis: 10
  RRF merged: axes=3

  1. UHQ 4.jpg         V=0.0529 S=0.6940  ← S축이 야경 의미 포착
  2. 야경_12.psd        S=0.7284 M=0.9581  ← S+M 복합 매칭
  3. 야경_4.psd         S=0.6870 M=0.3356
  4. 야경_11.psd        V=0.0461 M=0.9472
  5. 야경_9.psd         V=0.0459 M=0.9527
```

**핵심 발견:**
- S축이 V축보다 텍스트 의미를 훨씬 정확하게 포착 (S=0.73 vs V=0.05)
- S축이 없는 파일도 V축+M축으로 보완 가능 (3축 상호보완)
- 3축 모두 참여 시 RRF 병합이 가장 안정적인 순위 생성

### 5.6 효과

P0+P1 완료 상태에서 S축 추가:
- 87~97% → **90~97%** (추가 +3~7%p)
- 특히 V축이 약한 스타일라이즈 이미지에서 캡션 기반 복구력 향상

---

## 6. [P2+] Auto-Weighted RRF — **완료** (2026-02-08)

### 6.1 개요

3축(V, T, F) 검색에서 쿼리 유형에 따라 축별 가중치를 동적으로 조절.
QueryDecomposer가 query_type을 분류하고, 이에 맞는 가중치 프리셋을 적용.

### 6.2 가중치 프리셋 (채택: A)

```python
WEIGHT_PRESETS = {
    "visual":   {"visual": 0.50, "text_vec": 0.30, "fts": 0.20},  # 색감/분위기/스타일
    "keyword":  {"visual": 0.20, "text_vec": 0.30, "fts": 0.50},  # 특정 개체/키워드
    "semantic": {"visual": 0.20, "text_vec": 0.50, "fts": 0.30},  # 용도/맥락 설명
    "balanced": {"visual": 0.34, "text_vec": 0.33, "fts": 0.33},  # 복합/불명확
}
```

RRF 공식: `score(d) = w / (k + rank + 1)` (축별 가중치 w 적용)

### 6.3 config.yaml

```yaml
search:
  rrf:
    k: 60
    auto_weight: true          # query_type 기반 프리셋 자동 선택
    manual_weights:             # auto_weight: false일 때 사용
      visual: 0.34
      text_vec: 0.33
      fts: 0.33
```

### 6.4 QueryDecomposer 개선

- `/api/generate` → `/api/chat` 전환 (Ollama Chat API)
- Assistant prefix `<think>\n</think>\n{` 로 Qwen3 thinking 억제 (100s → 3s)
- `keep_alive: "5m"` 으로 모델 VRAM 상주 (재로드 60s 제거)
- `query_type` 필드 추가 (visual/keyword/semantic/balanced)

### 6.5 수정 파일

| 파일 | 작업 |
|------|------|
| `backend/search/rrf.py` | **신규** — 가중치 프리셋 + 재분배 로직 |
| `backend/search/query_decomposer.py` | **수정** — Chat API, thinking 억제, query_type |
| `backend/search/sqlite_search.py` | **수정** — weighted RRF + LLM 하드 필터 폐기 |
| `config.yaml` | **수정** — auto_weight: true |

### 6.6 ⚠️ 구조화 필터 폐기 (Critical Architectural Decision)

**배경:** P0에서 2-Stage Vision 파이프라인이 image_type, art_style, scene_type,
time_of_day 등의 구조화 분류 필드를 생성. 이를 검색 시 LLM 필터로 활용하려 했음.

**문제:** LLM이 생성한 필터를 AND 조건 하드 게이트로 적용하면 결과가 **100% 삭제됨**.

| 테스트 | RRF 병합 | 필터 후 | 원인 |
|--------|---------|--------|------|
| "야경" | 27건 | **0건** | scene_type="night scene" + time_of_day="night" |
| "anime night city" | 26건 | **0건** | art_style="anime" + scene_type="city" + time_of_day="night" |
| 6개 쿼리 전부 | 24~29건 | **전부 0건** | 구조화 필드 채워진 비율 ~5% |

**근본 원인 3가지:**

1. **DB 희소성** — 구조화 필드(scene_type, time_of_day 등)가 99파일 중 ~5%만 채워짐.
   AND 조건에서 하나라도 빈 필드가 있으면 탈락.

2. **3축과의 근본적 중복** — 구조화 필드가 하는 일을 3축이 이미 더 정확하게 수행:
   - `scene_type = "alley"` → M축(FTS)이 caption/tags의 "alley"를 직접 매칭
   - `art_style = "anime"` → V축(SigLIP 1152차원)이 시각적 스타일을 벡터로 인코딩
   - `time_of_day = "night"` → S축(Qwen3-Emb 1024차원)이 "night scene" 의미를 벡터화

3. **정보 차원의 비대칭** — 동일한 Qwen3-VL이 같은 이미지를 보고 생산하는 출력:
   - 자유형 caption/tags: 풍부한 서술 → 1152차원 + 1024차원으로 인코딩 (수천 가지 의미 표현)
   - 구조화 필드: ~10개 카테고리 강제 분류 (정보 손실이 수백 배)

**결론:**
- ❌ LLM 필터를 검색 하드 게이트로 사용하지 않음
- ✅ 구조화 필드는 DB에 저장 유지 (프론트엔드 수동 필터/정렬 용도)
- ✅ 검색 품질은 V+T+F 3축 Auto-Weighted RRF가 전담
- ✅ 2-Stage Vision 파이프라인은 유지 (타입별 프롬프트가 caption/tags 품질 향상)

---

## 7. [P3] 인프라 개선 — **미구현**

### 7.1 Python Subprocess → Long-Running Server

**현재:** 매 IPC 호출마다 Python 프로세스 스폰 (~200ms 오버헤드)
**계획:** FastAPI 서버 전환 → 모델 상주, 검색 지연 200ms → ~10ms

### 7.2 처리 큐 영속성

**현재:** 메모리 내 큐 → 크래시 시 소실
**계획:** SQLite `processing_queue` 테이블 → 앱 재시작 시 미완료 작업 자동 재개

### 7.3 MetadataModal 중복 제거

**현재:** SearchPanel.jsx와 FileGrid.jsx에 각각 인라인 구현
**계획:** `components/MetadataModal.jsx`로 분리

---

## 8. [P4] 서버형 전환 준비 — **미구현**

### 8.1 파일 경로 추상화

`storage_root` + `relative_path` 분리 (P0에서 스키마 선제 적용 완료)

### 8.2 임베딩 버전 관리

`embedding_model`, `embedding_version` 컬럼 (P0에서 선제 적용 완료)

### 8.3 멀티테넌시 고려

- 사용자별 네임스페이스 (`user_id` 컬럼)
- 오브젝트 스토리지 (S3/MinIO) 전환
- 인증/권한 레이어
- 태스크 큐 (Celery/Redis)

---

## 9. 성능 영향 요약

### 인제스트

| 항목 | P0 이전 | P0 후 | P0+P1 후 | P0+P1+P2 후 |
|------|---------|-------|---------|-------------|
| Vision 모델 | Qwen2.5-VL:7b | **Qwen3-VL:8b** | Qwen3-VL:8b | Qwen3-VL:8b |
| Ollama 호출 | 1회/이미지 | 2회/이미지 | 2회/이미지 | 2회/이미지 |
| V축 인코딩 | ~500ms (CLIP) | ~500ms (CLIP) | **~200ms (SigLIP 2)** | ~200ms |
| S축 인코딩 | - | - | - | **+~100ms** |
| 총 시간/이미지 | 5~15초 | 8~20초 | 8~18초 | 8~19초 |
| 인제스트 시 VRAM | ~1.5GB | **~6GB** | ~6.8GB | **~7.2GB** |

### 검색

| 항목 | P0 이전 | P0 후 | P0+P1 후 | P0+P1+P2 후 |
|------|---------|-------|---------|-------------|
| 검색 시 VRAM | ~1.5GB | ~1.5GB | **~0.8GB** | **~1.2GB** |
| 검색 지연 (200 파일) | ~20ms | ~20ms | ~20ms | ~25ms |
| 평균 적중률 | 30~40% | **85~95%** | **87~97%** | **90~97%** |
| 복합 쿼리 적중률 | 10~20% | **85~95%** | **87~95%** | **90~97%** |

### ROI 분석

| 단계 | 적중률 개선 | 구현 비용 | ROI |
|------|-----------|----------|-----|
| P0 (2-Stage + DB) | +45~55%p | 중간 | ★★★★★ |
| P1 (SigLIP 2) | +2~5%p | 낮음 | ★★★★ |
| P2 (S축) | +3~7%p | 중간 | ★★★ |
| P2+ (Auto-RRF) | +2~5%p | 낮음 | ★★★★ |
| P3 (인프라) | 적중률 무관 | 높음 | ★★★ |

---

## 부록 A: 공통 필드 정의

### art_style (전 타입 공통)

| 값 | 설명 |
|----|------|
| realistic | 사실적 묘사 |
| anime | 일본 애니메이션 스타일 |
| pixel | 픽셀 아트 |
| painterly | 회화적, 유화풍 |
| cartoon | 카툰, 서양 애니메이션 |
| 3d_render | 3D 렌더링 |
| chibi | SD 캐릭터 |
| sketch | 스케치, 라인아트 |
| flat_design | 플랫 디자인 |
| hand_drawn | 손그림 |
| photo | 실사 사진 |

### color_palette (전 타입 공통)

| 값 | 설명 |
|----|------|
| warm | 따뜻한 톤 (빨강, 주황, 노랑) |
| cool | 차가운 톤 (파랑, 보라, 청록) |
| monochrome | 단색 / 흑백 |
| vibrant | 선명하고 강렬한 색 |
| pastel | 파스텔 톤 |
| dark | 어두운 톤 |
| neutral | 중성 톤 (회색, 베이지) |
| earth_tone | 자연 톤 (갈색, 올리브) |
| neon | 네온/형광 |

---

## 부록 B: 모델 비교 상세

### Vision LLM: Qwen3-VL 패밀리

| 모델 | 파라미터 | Ollama 크기 | 컨텍스트 | 권장 용도 |
|------|---------|-----------|---------|----------|
| Qwen3-VL-2B | 2B | ~1.9GB | 256K | 경량 디바이스 |
| Qwen3-VL-4B | 4B | ~3.3GB | 256K | 모바일/저사양 |
| **Qwen3-VL-8B** | **8B** | **~6.1GB** | **256K** | **✅ ImageParser 사용** |
| Qwen3-VL-30B-A3B | 30B (Active 3B) | ~20GB | 256K | MoE, 고성능 대안 |

### V축 임베딩: SigLIP 2 패밀리

| 모델 | 파라미터 | 해상도 | ImageNet | 비고 |
|------|---------|--------|----------|------|
| SigLIP 2 ViT-B | 86M | 256 | ~80% | 초경량 |
| SigLIP 2 ViT-L | 303M | 256/384 | ~83% | 중간 |
| **SigLIP 2 So400m** | **400M** | **384 (NaFlex)** | **85.0%** | **✅ ImageParser 사용** |
| SigLIP 2 ViT-g | 1B | 384 | ~86% | 고성능 대안 |

### S축 임베딩: Qwen3-Embedding 패밀리

| 모델 | 파라미터 | Ollama 크기 | 최대 차원 | 컨텍스트 |
|------|---------|-----------|----------|---------|
| **Qwen3-Embedding-0.6B** | **0.6B** | **~400MB** | **1024** | **32K** |
| Qwen3-Embedding-4B | 4B | ~2.5GB | 2048 | 32K |
| Qwen3-Embedding-8B | 8B | ~5GB | 4096 | 32K |

---

## 부록 C: 포지셔닝

| 비교 대상 | ImageParser 우위 | 상대방 우위 |
|-----------|-----------------|------------|
| Eagle | AI 자동 분류, 벡터 유사도, PSD 파싱 | UI 완성도, 브라우저 익스텐션 |
| Adobe Bridge | 로컬 LLM 자연어 검색, 2-Stage 분류 | Adobe 생태계, XMP |
| Pinecone+CLIP | 올인원 데스크톱, 3축 하이브리드 | 스케일(수백만 벡터) |
| Google Photos | PSD 지원, 레이어 분석, 프라이버시 | 얼굴 인식, 자동 분류 정확도 |

**ImageParser 고유 차별점:**
- PSD 레이어 구조까지 파싱하여 검색 가능한 유일한 로컬 AI 도구
- 2-Stage 자동 분류로 게임/디자인 에셋 도메인 특화
- Triaxis RRF 검색 (3축 + Auto-Weighted)
- 최신 모델 스택: Qwen3-VL + SigLIP 2 + Qwen3-Embedding
- 로컬 실행으로 완전한 데이터 프라이버시
- Apache 2.0 모델만 사용 → 상업 전환 무제약

---

## 부록 D: 라이선스 요약

| 모델 | 용도 | 라이선스 | 상업 이용 |
|------|------|---------|----------|
| Qwen3-VL-8B | Vision LLM | Apache 2.0 | ✅ 자유 |
| SigLIP 2 So400m | V축 임베딩 | Apache 2.0 | ✅ 자유 |
| Qwen3-Embedding-0.6B | S축 임베딩 | Apache 2.0 | ✅ 자유 |

⚠️ Jina CLIP v2 (CC-BY-NC)와 Jina Embeddings v3 (CC-BY-NC)를 제외한 이유: 비상업 라이선스는 서비스 전환 시 별도 라이선스 협상 필요. 전 모델 Apache 2.0 통일으로 법적 리스크 제로.

---
